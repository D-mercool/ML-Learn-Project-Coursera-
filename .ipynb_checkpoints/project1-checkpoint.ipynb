{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('features.csv', index_col='match_id')\n",
    "X = data.iloc[:, :102]\n",
    "y = data['radiant_win']\n",
    "\n",
    "data_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.\n",
    "\n",
    "3) Замените пропуски на нули с помощью функции fillna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_prop = []\n",
    "for i in range(102):\n",
    "    if X.count()[i] != 97230:\n",
    "        mass_prop.append(X.iloc[:,i].name)\n",
    "\n",
    "X = X.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Название признаков, имеющих пропуски'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['first_blood_time',\n",
       " 'first_blood_team',\n",
       " 'first_blood_player1',\n",
       " 'first_blood_player2',\n",
       " 'radiant_bottle_time',\n",
       " 'radiant_courier_time',\n",
       " 'radiant_flying_courier_time',\n",
       " 'radiant_first_ward_time',\n",
       " 'dire_bottle_time',\n",
       " 'dire_courier_time',\n",
       " 'dire_flying_courier_time',\n",
       " 'dire_first_ward_time']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Название признаков, имеющих пропуски\", mass_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Например, признак 'first_blood_time', что означает время первого убийства в игре, может отсутствовать по причине того, что за первые 5 минут игры ни один из игроков не умер, следовательно это признак пуст. Признак 'radiant_courier_time', что означает время поупки курьера, также может отсутствовать по причине того, что команда 'Radient' не купила курьера за первые 5 минут игры.\n",
    "\n",
    "4) Какой столбец содержит целевую переменную? Запишите его название."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match_id\n",
       "0         1\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "114402    0\n",
       "114403    1\n",
       "114404    0\n",
       "114405    0\n",
       "114406    1\n",
       "Name: radiant_win, Length: 97230, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Столбец 'radiant_win' содержит целевую переменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 1: градиентный бустинг \"в лоб\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 30, 40, 50]\n",
    "mass = []\n",
    "times = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "for i in n_estimators:\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "    gb = GradientBoostingClassifier(n_estimators=i, random_state=241, max_depth=2)\n",
    "    gb.fit(X, y)\n",
    "    scores = cross_val_score(gb, X, y, cv=kf, scoring='roc_auc')\n",
    "    mass.append(scores)\n",
    "    \n",
    "    times.append(datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.65579464, 0.64187792, 0.65037059, 0.65524734, 0.65092211]), array([0.67890027, 0.66540691, 0.67360983, 0.67477584, 0.67495895]), array([0.68925707, 0.67549772, 0.68101969, 0.68375468, 0.68581689]), array([0.69452829, 0.68145108, 0.68611001, 0.68773872, 0.6897242 ]), array([0.69832237, 0.68587487, 0.68975063, 0.69070186, 0.69310454])]\n",
      "[datetime.timedelta(seconds=38, microseconds=840994), datetime.timedelta(seconds=71, microseconds=908493), datetime.timedelta(seconds=103, microseconds=277146), datetime.timedelta(seconds=131, microseconds=398079), datetime.timedelta(seconds=160, microseconds=267934)]\n"
     ]
    }
   ],
   "source": [
    "print(mass)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Кросс-валидация для градиентного бустинга с 30 деревьями имеет время настройки 103 секунды\n",
    "    \n",
    "    Лучшее качество градиентного бустинга достигнуто, примерно 0.685 при n_estimators = 30 и  0.69 при n_estimators = 40. Классификатор настраивался долго. Как видно, достингнуто оптимальное качетвоа так как, качетво не должно расти при росте числа деревьев, либо растет, но незначительно. следовательно нет смысл использовать больше 30 деревьев в градиентном бустинге.\n",
    "    \n",
    "    Чтобы ускорить обучение при увеличении количества деревьев, я упрощал модель, использую max_depth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "mass = []\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "for i in C:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "    lg = LogisticRegression(penalty='l2', random_state=241, C=i, solver='lbfgs')\n",
    "    lg.fit(X, y)\n",
    "    scores = cross_val_score(lg, X, y, cv=kf, scoring='roc_auc')\n",
    "    mass.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.72134691, 0.71368543, 0.7142503 , 0.71511826, 0.716496  ]),\n",
       " array([0.72166336, 0.71377455, 0.7144095 , 0.7154027 , 0.71646035]),\n",
       " array([0.72165999, 0.71370262, 0.71439004, 0.71539378, 0.71640597]),\n",
       " array([0.72165968, 0.71369426, 0.71438569, 0.71539326, 0.71640028]),\n",
       " array([0.72165847, 0.71369387, 0.71438513, 0.71539504, 0.71639887]),\n",
       " array([0.72165854, 0.71369377, 0.71438504, 0.7153948 , 0.71640154]),\n",
       " array([0.72165852, 0.7136937 , 0.71438502, 0.71539475, 0.7164022 ])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший параметр регуляризации C = 0.01. Наилучшее качество  0.72. Логистическая регрессия работает быстрее градиентного бустинга, и лучше по качеству.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('features.csv', index_col='match_id')\n",
    "X = data.iloc[:, :102]\n",
    "y = data['radiant_win']\n",
    "\n",
    "data_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test = data_test\n",
    "\n",
    "X = X.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "del X['lobby_type']\n",
    "for i in range(1,6):\n",
    "    del X['r'+str(i)+'_hero']\n",
    "    del X['d'+str(i)+'_hero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = []\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "grid = {'C': np.power(10.0, np.arange(-5,6))}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "lg = LogisticRegression(penalty='l2', random_state=241, solver='lbfgs')\n",
    "gs = GridSearchCV(lg, grid, scoring='roc_auc', cv=kf)\n",
    "gs.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(lg, X, y, cv=kf, scoring='roc_auc')\n",
    "mass.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.45552368, 0.50249729, 0.82209506, 1.18991156, 1.19189386,\n",
       "        1.25988736, 1.23083825, 1.25682731, 1.24284654, 1.30579638,\n",
       "        1.25587482]),\n",
       " 'std_fit_time': array([0.0272085 , 0.01554925, 0.02845215, 0.08291699, 0.09083502,\n",
       "        0.04590073, 0.03661275, 0.07078653, 0.07645949, 0.05034263,\n",
       "        0.06168946]),\n",
       " 'mean_score_time': array([0.01538229, 0.0145854 , 0.01338758, 0.01621981, 0.01602063,\n",
       "        0.014569  , 0.01499014, 0.01518559, 0.01377444, 0.01618509,\n",
       "        0.01598663]),\n",
       " 'std_score_time': array([0.00162398, 0.00149683, 0.00049171, 0.002279  , 0.00259012,\n",
       "        0.00212546, 0.00167189, 0.00213584, 0.00098422, 0.00271266,\n",
       "        0.00379193]),\n",
       " 'param_C': masked_array(data=[1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                    1000.0, 10000.0, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 1.0},\n",
       "  {'C': 10.0},\n",
       "  {'C': 100.0},\n",
       "  {'C': 1000.0},\n",
       "  {'C': 10000.0},\n",
       "  {'C': 100000.0}],\n",
       " 'split0_test_score': array([0.69960017, 0.71628682, 0.72152485, 0.72181625, 0.72181202,\n",
       "        0.72181077, 0.72181106, 0.72181123, 0.72181114, 0.72181115,\n",
       "        0.72181115]),\n",
       " 'split1_test_score': array([0.69148876, 0.70827317, 0.7136096 , 0.71370029, 0.71363853,\n",
       "        0.71362888, 0.71362799, 0.71362796, 0.71362789, 0.71362792,\n",
       "        0.71362792]),\n",
       " 'split2_test_score': array([0.69420354, 0.70971968, 0.7144559 , 0.71462426, 0.71460838,\n",
       "        0.7146083 , 0.71460898, 0.71460886, 0.71460885, 0.71460886,\n",
       "        0.71460886]),\n",
       " 'split3_test_score': array([0.69424161, 0.71019908, 0.71521473, 0.71551483, 0.71550902,\n",
       "        0.71551056, 0.7155093 , 0.71550897, 0.71550887, 0.71550885,\n",
       "        0.71550884]),\n",
       " 'split4_test_score': array([0.69572094, 0.71173161, 0.71636923, 0.71634683, 0.71630481,\n",
       "        0.71629626, 0.71629678, 0.71629601, 0.71629608, 0.71629607,\n",
       "        0.71629605]),\n",
       " 'mean_test_score': array([0.695051  , 0.71124207, 0.71623486, 0.71640049, 0.71637455,\n",
       "        0.71637095, 0.71637082, 0.71637061, 0.71637057, 0.71637057,\n",
       "        0.71637056]),\n",
       " 'std_test_score': array([0.00265355, 0.00275351, 0.0027964 , 0.00284829, 0.00286095,\n",
       "        0.00286229, 0.00286255, 0.00286266, 0.00286265, 0.00286265,\n",
       "        0.00286265]),\n",
       " 'rank_test_score': array([11, 10,  9,  1,  2,  3,  4,  5,  7,  6,  8])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Качество практичечки не изменилось, это можно объяснить тем, что модель не учитывала категориальные признаки, а сейчас мы их удалили и убелись в этом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 112]\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('features.csv', index_col='match_id')\n",
    "X = data.iloc[:, :102]\n",
    "y = data['radiant_win']\n",
    "\n",
    "data_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test = data_test\n",
    "\n",
    "X = X.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(sorted(X['d1_hero'].unique()))\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(len(X['r'+str(i)+'_hero'].unique()))\n",
    "    print(len(X['d'+str(i)+'_hero'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Как можно видеть из данных, существует всего 108 различных идентификтаоров героев. Последний идентификатор заканчивается на 112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>r2_level</th>\n",
       "      <th>r2_xp</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1430198770</td>\n",
       "      <td>5</td>\n",
       "      <td>2098</td>\n",
       "      <td>1489</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1430220345</td>\n",
       "      <td>4</td>\n",
       "      <td>1188</td>\n",
       "      <td>1033</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1430227081</td>\n",
       "      <td>4</td>\n",
       "      <td>1319</td>\n",
       "      <td>1270</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1430263531</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>1056</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1430282290</td>\n",
       "      <td>4</td>\n",
       "      <td>1431</td>\n",
       "      <td>1090</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97225</td>\n",
       "      <td>1450265551</td>\n",
       "      <td>4</td>\n",
       "      <td>1706</td>\n",
       "      <td>1198</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97226</td>\n",
       "      <td>1450277704</td>\n",
       "      <td>4</td>\n",
       "      <td>1793</td>\n",
       "      <td>1416</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97227</td>\n",
       "      <td>1450291848</td>\n",
       "      <td>4</td>\n",
       "      <td>1399</td>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97228</td>\n",
       "      <td>1450292986</td>\n",
       "      <td>3</td>\n",
       "      <td>1135</td>\n",
       "      <td>766</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97229</td>\n",
       "      <td>1450313370</td>\n",
       "      <td>3</td>\n",
       "      <td>1053</td>\n",
       "      <td>799</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97230 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_time  r1_level  r1_xp  r1_gold  r1_lh  r1_kills  r1_deaths  \\\n",
       "0      1430198770         5   2098     1489     20         0          0   \n",
       "1      1430220345         4   1188     1033      9         0          1   \n",
       "2      1430227081         4   1319     1270     22         0          0   \n",
       "3      1430263531         4   1779     1056     14         0          0   \n",
       "4      1430282290         4   1431     1090      8         1          0   \n",
       "...           ...       ...    ...      ...    ...       ...        ...   \n",
       "97225  1450265551         4   1706     1198     17         0          1   \n",
       "97226  1450277704         4   1793     1416     17         0          1   \n",
       "97227  1450291848         4   1399      540      1         0          0   \n",
       "97228  1450292986         3   1135      766      6         0          2   \n",
       "97229  1450313370         3   1053      799      7         0          0   \n",
       "\n",
       "       r1_items  r2_level  r2_xp  ...  102  103  104  105  106  107  108  109  \\\n",
       "0             7         3    842  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1            12         4   1596  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2            12         3   1314  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3             5         2    539  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4             8         2    629  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "97225         8         2    616  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "97226         5         3    764  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "97227         5         4   1448  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "97228         6         5   1954  ...  0.0  0.0  0.0 -1.0  0.0  0.0  0.0  0.0   \n",
       "97229         7         5   2097  ...  0.0  0.0  0.0 -1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       110  111  \n",
       "0      0.0  0.0  \n",
       "1      0.0  0.0  \n",
       "2      0.0  0.0  \n",
       "3      0.0  0.0  \n",
       "4      0.0  0.0  \n",
       "...    ...  ...  \n",
       "97225  0.0  0.0  \n",
       "97226  0.0  0.0  \n",
       "97227  0.0  1.0  \n",
       "97228  0.0  0.0  \n",
       "97229  0.0 -1.0  \n",
       "\n",
       "[97230 rows x 203 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 112\n",
    "X_pick = np.zeros((X.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(X.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, X.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_pick = pd.DataFrame(X_pick)\n",
    "del X['lobby_type']\n",
    "del X_test['lobby_type']\n",
    "for i in range(1,6):\n",
    "    del X['r'+str(i)+'_hero']\n",
    "    del X['d'+str(i)+'_hero']\n",
    "    del X_test['r'+str(i)+'_hero']\n",
    "    del X_test['d'+str(i)+'_hero']\n",
    "\n",
    "X.index = np.arange(97230)\n",
    "X_test.index = np.arange(17177)\n",
    "\n",
    "X = X.join(X_pick)\n",
    "\n",
    "#X = X.iloc[:10000]\n",
    "\n",
    "X_test = X_test.join(X_pick)\n",
    "\n",
    "#X_test = X_test.iloc[:10000]\n",
    "#y = y[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = []\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "grid = {'C': np.power(10.0, np.arange(-5,6))}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "lg = LogisticRegression(penalty='l2', random_state=241, solver='lbfgs')\n",
    "gs = GridSearchCV(lg, grid, scoring='roc_auc', cv=kf)\n",
    "gs.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(lg, X, y, cv=kf, scoring='roc_auc')\n",
    "mass.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Полученное качество\n",
    "Качество улучшилось, так как мы правильно описали категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.75512029, 0.74989619, 0.75212706, 0.74953815, 0.75290589])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.89984779, 1.07913575, 1.72093873, 2.47166958, 3.43426757,\n",
       "        2.48386412, 2.53861399, 2.47802267, 2.49342709, 2.48935318,\n",
       "        2.484589  ]),\n",
       " 'std_fit_time': array([0.03332061, 0.10885725, 0.12274122, 0.0923274 , 0.60673411,\n",
       "        0.01895641, 0.05241989, 0.04183304, 0.02396092, 0.02886847,\n",
       "        0.02436187]),\n",
       " 'mean_score_time': array([0.02178078, 0.02018218, 0.02118206, 0.02558246, 0.05596409,\n",
       "        0.01878481, 0.01904511, 0.02018704, 0.01775684, 0.01980748,\n",
       "        0.02017937]),\n",
       " 'std_score_time': array([4.07046575e-03, 3.36916561e-03, 2.31468735e-03, 5.67466666e-03,\n",
       "        6.94934370e-02, 3.99865940e-04, 9.37536432e-04, 3.26100841e-05,\n",
       "        3.91131789e-03, 8.13125823e-04, 3.51042839e-05]),\n",
       " 'param_C': masked_array(data=[1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                    1000.0, 10000.0, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 1.0},\n",
       "  {'C': 10.0},\n",
       "  {'C': 100.0},\n",
       "  {'C': 1000.0},\n",
       "  {'C': 10000.0},\n",
       "  {'C': 100000.0}],\n",
       " 'split0_test_score': array([0.71906069, 0.74684196, 0.75515191, 0.75521636, 0.75513042,\n",
       "        0.75512029, 0.75512052, 0.75512072, 0.75512079, 0.75512078,\n",
       "        0.75512079]),\n",
       " 'split1_test_score': array([0.71115519, 0.74005455, 0.74930934, 0.74985827, 0.74989125,\n",
       "        0.74989619, 0.74989656, 0.74989664, 0.74989657, 0.74989656,\n",
       "        0.74989656]),\n",
       " 'split2_test_score': array([0.71513389, 0.74277445, 0.75181807, 0.75218087, 0.75213456,\n",
       "        0.75212706, 0.75212817, 0.75212553, 0.75212556, 0.75212553,\n",
       "        0.75212552]),\n",
       " 'split3_test_score': array([0.71285869, 0.7402515 , 0.74901093, 0.74950989, 0.74953492,\n",
       "        0.74953815, 0.749539  , 0.7495391 , 0.74953918, 0.74953917,\n",
       "        0.74953917]),\n",
       " 'split4_test_score': array([0.71586848, 0.74423718, 0.75305403, 0.75308918, 0.75292999,\n",
       "        0.75290589, 0.75290244, 0.75290202, 0.752902  , 0.75290201,\n",
       "        0.75290201]),\n",
       " 'mean_test_score': array([0.71481539, 0.74283193, 0.75166885, 0.75197092, 0.75192423,\n",
       "        0.75191752, 0.75191734, 0.7519168 , 0.75191682, 0.75191681,\n",
       "        0.75191681]),\n",
       " 'std_test_score': array([0.00270032, 0.0025468 , 0.00231104, 0.00211412, 0.00205802,\n",
       "        0.00205064, 0.00205013, 0.00205007, 0.00205008, 0.00205008,\n",
       "        0.00205009]),\n",
       " 'rank_test_score': array([11, 10,  9,  1,  2,  3,  4,  8,  5,  6,  7])}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, лучший результат получается при С = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Можно сделать вывод, что из  логистической регрессии получается более верная модель (0.75 > 0.69). Сделаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное значение:  0.00472219927337751\n",
      "Максимальное значение:  0.9974818227361194\n"
     ]
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "pred = gs.predict_proba(X_test)[:, 1]\n",
    "print('Минимальное значение: ', pred.min())\n",
    "print('Максимальное значение: ', pred.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
